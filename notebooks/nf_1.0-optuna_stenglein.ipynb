{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary Least Squares on magnet challenge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.integrate import trapezoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           B_t_0     B_t_1     B_t_2     B_t_3     B_t_4     B_t_5     B_t_6  \\\n",
      "0       0.000543  0.000738  0.000931  0.001125  0.001318  0.001512  0.001705   \n",
      "1       0.001237  0.001455  0.001672  0.001889  0.002105  0.002322  0.002539   \n",
      "2      -0.000301 -0.000056  0.000188  0.000433  0.000677  0.000922  0.001166   \n",
      "3      -0.000294 -0.000020  0.000254  0.000527  0.000801  0.001075  0.001349   \n",
      "4      -0.000164  0.000141  0.000447  0.000752  0.001058  0.001364  0.001669   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "156279 -0.010075 -0.009807 -0.009543 -0.009283 -0.009027 -0.008776 -0.008527   \n",
      "156280 -0.011321 -0.011023 -0.010727 -0.010436 -0.010149 -0.009867 -0.009588   \n",
      "156281 -0.012659 -0.012325 -0.011992 -0.011665 -0.011342 -0.011025 -0.010711   \n",
      "156282 -0.014078 -0.013703 -0.013331 -0.012965 -0.012604 -0.012249 -0.011897   \n",
      "156283 -0.015670 -0.015251 -0.014835 -0.014426 -0.014023 -0.013626 -0.013233   \n",
      "\n",
      "           B_t_7     B_t_8     B_t_9  ...  B_t_1019  B_t_1020  B_t_1021  \\\n",
      "0       0.001899  0.002092  0.002285  ... -0.000425 -0.000232 -0.000038   \n",
      "1       0.002756  0.002974  0.003190  ...  0.000151  0.000368  0.000585   \n",
      "2       0.001411  0.001656  0.001900  ... -0.001525 -0.001281 -0.001036   \n",
      "3       0.001622  0.001894  0.002167  ... -0.001663 -0.001389 -0.001115   \n",
      "4       0.001973  0.002278  0.002584  ... -0.001690 -0.001385 -0.001080   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "156279 -0.008280 -0.008034 -0.007787  ... -0.011294 -0.011086 -0.010854   \n",
      "156280 -0.009312 -0.009036 -0.008760  ... -0.012658 -0.012433 -0.012180   \n",
      "156281 -0.010400 -0.010090 -0.009779  ... -0.014156 -0.013905 -0.013623   \n",
      "156282 -0.011548 -0.011200 -0.010851  ... -0.015773 -0.015486 -0.015163   \n",
      "156283 -0.012843 -0.012454 -0.012065  ... -0.017584 -0.017255 -0.016889   \n",
      "\n",
      "        B_t_1022  B_t_1023      freq          ploss  temp  material  b_sat_25  \n",
      "0       0.000155  0.000349   50020.0    2319.444340    25      3C90      0.47  \n",
      "1       0.000802  0.001019   50020.0    3191.235893    25      3C90      0.47  \n",
      "2      -0.000792 -0.000547   50020.0    4341.086142    25      3C90      0.47  \n",
      "3      -0.000842 -0.000568   50020.0    5795.359190    25      3C90      0.47  \n",
      "4      -0.000775 -0.000470   50030.0    7813.691725    25      3C90      0.47  \n",
      "...          ...       ...       ...            ...   ...       ...       ...  \n",
      "156279 -0.010603 -0.010342  446420.0   61790.145402    25       N87      0.49  \n",
      "156280 -0.011906 -0.011617  446420.0   78810.500010    25       N87      0.49  \n",
      "156281 -0.013315 -0.012992  446420.0  100717.381914    25       N87      0.49  \n",
      "156282 -0.014816 -0.014451  446420.0  129153.194834    25       N87      0.49  \n",
      "156283 -0.016497 -0.016088  446420.0  165612.702450    25       N87      0.49  \n",
      "\n",
      "[46915 rows x 1029 columns]\n"
     ]
    }
   ],
   "source": [
    "filepath = '/home/nikolasf/Dokumente/01_git/30_Python/MC_UPB/data/input/processed'\n",
    "material_name = 'ten_materials'\n",
    "ds = pd.read_pickle(f'{filepath}/{material_name}.pkl.gz')\n",
    "\n",
    "ds = ds.drop(columns=[c for c in ds if c.startswith(\"H_t\")])\n",
    "\n",
    "ds = ds.query('temp == 25')\n",
    "\n",
    "# add the saturation flux density. Data from datasheets.\n",
    "ds.loc[ds['material'] == '3C90', 'b_sat_25'] = 0.47\n",
    "ds.loc[ds['material'] == '3C94', 'b_sat_25'] = 0.47\n",
    "ds.loc[ds['material'] == '3E6', 'b_sat_25'] = 0.46\n",
    "ds.loc[ds['material'] == '3F4', 'b_sat_25'] = 0.41\n",
    "ds.loc[ds['material'] == '77', 'b_sat_25'] = 0.51\n",
    "ds.loc[ds['material'] == '78', 'b_sat_25'] = 0.48\n",
    "ds.loc[ds['material'] == 'N27', 'b_sat_25'] = 0.50\n",
    "ds.loc[ds['material'] == 'N30', 'b_sat_25'] = 0.38\n",
    "ds.loc[ds['material'] == 'N49', 'b_sat_25'] = 0.49\n",
    "ds.loc[ds['material'] == 'N87', 'b_sat_25'] = 0.49\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapted Wilhelm example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run linear regression with regularization training\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor, GradientBoostingRegressor, VotingRegressor, ExtraTreesRegressor\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from utils.experiments import get_stratified_fold_indices, PROC_SOURCE\n",
    "from utils.metrics import calculate_metrics\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 500)\n",
    "    print(f'{n_estimators = }')\n",
    "    criterion = trial.suggest_categorical('criterion', ['absolute_error', 'squared_error'])\n",
    "    print(f\"{criterion = }\")\n",
    "    \n",
    "    exp_log = {}\n",
    "    for material_lbl, mat_df in tqdm(ds.groupby(\"material\"), desc=\"Train across materials\"):\n",
    "        full_b = mat_df.loc[:, [f\"B_t_{k}\" for k in range(1024)]].to_numpy()\n",
    "        dbdt = full_b[:, 1:] - full_b[:, :-1]\n",
    "        mat_df = mat_df.reset_index(drop=True)\n",
    "\n",
    "        x_vec = np.linspace(0, 1023, 1024)\n",
    "        b_vec = []\n",
    "        for value in x_vec:\n",
    "            b_vec.append(f'B_t_{int(value)}')\n",
    "        mat_df[\"b\"] = mat_df[b_vec].values.tolist()\n",
    "        x_vec = None\n",
    "        b_vec = None\n",
    "        mat_df['delta_b'] = mat_df['b'].map(lambda x: np.max(x) - np.min(x))\n",
    "\n",
    "        # figure out integral_part \n",
    "        mat_df[\"time_s\"] = mat_df[\"freq\"].map(lambda x: np.linspace(0, 1/x, 1024))\n",
    "\n",
    "        # derivation\n",
    "        # according to https://im-coder.com/zweite-ableitung-in-python-scipy-numpy-pandas.html\n",
    "        mat_df[\"fitted_function\"] = mat_df.apply(lambda x: UnivariateSpline(x[\"time_s\"], x[\"b\"], s=0, k=4), axis=1)\n",
    "        mat_df[\"amplitude_2nd_derivation\"] = mat_df[\"fitted_function\"].apply(lambda x: x.derivative(n=2))\n",
    "        mat_df[\"integrated_function\"] = mat_df.apply(lambda x: trapezoid(np.abs(x[\"amplitude_2nd_derivation\"](x[\"time_s\"])), x[\"time_s\"]), axis=1)     \n",
    "\n",
    "        mat_df[\"integral_part\"] = mat_df[\"integrated_function\"] / mat_df[\"delta_b\"]\n",
    "\n",
    "        # cross validation 'kfold'\n",
    "        kfold_lbls = get_stratified_fold_indices(mat_df, 4)\n",
    "        mat_df_proc = mat_df.assign(\n",
    "            kfold=kfold_lbls,\n",
    "            # integral_part=mat_df['integral_part'],\n",
    "            #delta_b=mat_df['delta_b'],\n",
    "            #b_sat=mat_df['b_sat_25'],\n",
    "            db_bsat_1 = mat_df['delta_b'] / mat_df['b_sat_25'],\n",
    "            db_bsat_2 = (mat_df['delta_b'] / mat_df['b_sat_25']) ** 2,\n",
    "            db_bsat_3 = (mat_df['delta_b'] / mat_df['b_sat_25']) ** 3,\n",
    "            db_bsat_4 = (mat_df['delta_b'] / mat_df['b_sat_25']) ** 4,\n",
    "            db_bsat_5 = (mat_df['delta_b'] / mat_df['b_sat_25']) ** 5,\n",
    "            db_bsat_6 = (mat_df['delta_b'] / mat_df['b_sat_25']) ** 6,\n",
    "            t0 = 1,\n",
    "            t1 = 0,\n",
    "            t2 = (mat_df['integral_part'] ** (-1)) / 2,\n",
    "            t3 = -(mat_df['integral_part'] ** (-2)) / 6,\n",
    "            t4 = ( 3 * mat_df['integral_part'] ** (-2) + 2 * mat_df['integral_part'] ** (-3)) / 24\n",
    "            # more features imaginable (count of spikes e.g.)\n",
    "        ).drop(\n",
    "            columns=[c for c in mat_df if c.startswith(\"B_t_\")] + [\"material\"] + ['b'] + ['time_s'] + ['fitted_function'] +['amplitude_2nd_derivation'] + ['integrated_function'] + ['temp'] + ['b_sat_25']\n",
    "        )  # drop B curve\n",
    "\n",
    "        # training result container\n",
    "        results_df = mat_df_proc.loc[:, [\"ploss\", \"kfold\"]].assign(pred=0)\n",
    "        x_cols = [c for c in mat_df_proc if c not in [\"ploss\", \"kfold\"]]\n",
    "        print(x_cols)\n",
    "        for kfold_lbl, test_fold_df in mat_df_proc.groupby(\"kfold\"):\n",
    "            train_fold_df = (\n",
    "                mat_df_proc.query(\"kfold != @kfold_lbl\")\n",
    "                .reset_index(drop=True)\n",
    "                .drop(columns=\"kfold\")\n",
    "            )\n",
    "            assert len(train_fold_df) > 0, \"empty dataframe error\"\n",
    "            y = train_fold_df.pop(\"ploss\")\n",
    "            X = train_fold_df.loc[:, x_cols]\n",
    "\n",
    "            mdl = ExtraTreesRegressor(n_estimators=n_estimators, criterion=criterion) # GradientBoostingRegressor() # HistGradientBoostingRegressor() # RandomForestRegressor(n_estimators = 100) #LinearRegression() # Ridge()  # \n",
    "            mdl.fit(X.to_numpy(), y.to_numpy())\n",
    "            pred = mdl.predict(test_fold_df.loc[:, x_cols].to_numpy())\n",
    "            results_df.loc[results_df.kfold == kfold_lbl, \"pred\"] = pred\n",
    "\n",
    "        # book keeping\n",
    "        exp_log[material_lbl] = calculate_metrics(\n",
    "            results_df.loc[:, \"pred\"], results_df.loc[:, \"ploss\"]\n",
    "        )\n",
    "    print(mdl.__class__.__name__)\n",
    "    #print(mdl.features_importances_)\n",
    "    print(\"Overall Score\")\n",
    "    score = pd.DataFrame(exp_log).T\n",
    "    print(score)\n",
    "\n",
    "    added_avg_abs_rel_err = score['avg-abs-rel-err'].sum()\n",
    "    print('sum error')\n",
    "    print(added_avg_abs_rel_err)\n",
    "    \n",
    "    return added_avg_abs_rel_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(mdl.features_importances_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run objective function single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run objective function in a hyperparameter optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 11:03:51,380] A new study created in memory with name: no-name-30368f07-f9a3-4c47-b2a7-cbc4e4b2fbaf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 458\n",
      "criterion = 'squared_error'\n",
      "n_estimators = 276\n",
      "criterion = 'absolute_error'\n",
      "n_estimators = 402\n",
      "criterion = 'absolute_error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train across materials:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import sklearn.model_selection\n",
    "import sklearn.svm\n",
    "\n",
    "\n",
    "# FYI: Objective functions can take additional arguments\n",
    "# (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "#study.optimize(objective, n_trials=20, n_jobs=3)\n",
    "#print(study.best_trial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "862f57f7b4a9bcb8e62a2c8b5a26d37db35f8703e11463ebdedd88c83882dd1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
