{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary Least Squares on magnet challenge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.integrate import trapezoid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3C90' '3F4' '78' '77' 'N49' '3E6' 'N27' 'N30' '3C94' 'N87']\n"
     ]
    }
   ],
   "source": [
    "filepath = '/home/nikolasf/Dokumente/01_git/30_Python/MC_UPB/data/input/processed'\n",
    "material_name = 'ten_materials'\n",
    "ds = pd.read_pickle(f'{filepath}/{material_name}.pkl.gz')\n",
    "\n",
    "print(pd.unique(ds[\"material\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial edit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           2319.444340\n",
      "1           3191.235893\n",
      "2           4341.086142\n",
      "3           5795.359190\n",
      "4           7813.691725\n",
      "              ...      \n",
      "186742     68121.464932\n",
      "186743     85924.743654\n",
      "186744    108411.839417\n",
      "186745    135853.384296\n",
      "186746    171849.522231\n",
      "Name: ploss, Length: 186747, dtype: float64\n",
      "0          7.749083\n",
      "1          8.068164\n",
      "2          8.375880\n",
      "3          8.664813\n",
      "4          8.963633\n",
      "            ...    \n",
      "186742    11.129048\n",
      "186743    11.361227\n",
      "186744    11.593693\n",
      "186745    11.819332\n",
      "186746    12.054375\n",
      "Name: ploss, Length: 186747, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ds = ds.drop(columns=[c for c in ds if c.startswith(\"H_t\")])\n",
    "#ds = ds.query('temp == 25')\n",
    "\n",
    "# add the saturation flux density. Data from datasheets.\n",
    "ds.loc[ds['material'] == '3C90', 'b_sat_25'] = 0.47\n",
    "ds.loc[ds['material'] == '3C94', 'b_sat_25'] = 0.47\n",
    "ds.loc[ds['material'] == '3E6', 'b_sat_25'] = 0.46\n",
    "ds.loc[ds['material'] == '3F4', 'b_sat_25'] = 0.41\n",
    "ds.loc[ds['material'] == '77', 'b_sat_25'] = 0.51\n",
    "ds.loc[ds['material'] == '78', 'b_sat_25'] = 0.48\n",
    "ds.loc[ds['material'] == 'N27', 'b_sat_25'] = 0.50\n",
    "ds.loc[ds['material'] == 'N30', 'b_sat_25'] = 0.38\n",
    "ds.loc[ds['material'] == 'N49', 'b_sat_25'] = 0.49\n",
    "ds.loc[ds['material'] == 'N87', 'b_sat_25'] = 0.49\n",
    "\n",
    "\n",
    "print(ds['ploss'])\n",
    "ds['ploss'] = np.log(ds['ploss'])\n",
    "ds['freq'] = np.log(ds['freq'])\n",
    "\n",
    "print(ds['ploss'])\n",
    "\n",
    "# print(ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapted Wilhelm example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run linear regression with regularization training\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor, GradientBoostingRegressor, VotingRegressor, ExtraTreesRegressor\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from utils.experiments import get_stratified_fold_indices, PROC_SOURCE\n",
    "from utils.metrics import calculate_metrics\n",
    "import xgboost as xgb\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "\n",
    "\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 800)\n",
    "    # 429 is best\n",
    "    print(f'{n_estimators = }')\n",
    "    criterion = trial.suggest_categorical('criterion', ['squared_error'])\n",
    "    print(f\"{criterion = }\")\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.5)\n",
    "    # 0.12 is best\n",
    "    print(f\"{learning_rate = }\")\n",
    "    \n",
    "    exp_log = {}\n",
    "    for material_lbl, mat_df in tqdm(ds.groupby(\"material\"), desc=\"Train across materials\"):\n",
    "\n",
    "        full_b = mat_df.loc[:, [f\"B_t_{k}\" for k in range(1024)]].to_numpy()\n",
    "\n",
    "        dbdt = full_b[:, 1:] - full_b[:, :-1]\n",
    "        mat_df = mat_df.reset_index(drop=True)\n",
    "\n",
    "        x_vec = np.linspace(0, 1023, 1024)\n",
    "        b_vec = []\n",
    "        for value in x_vec:\n",
    "            b_vec.append(f'B_t_{int(value)}')\n",
    "        mat_df[\"b\"] = mat_df[b_vec].values.tolist()\n",
    "        x_vec = None\n",
    "        b_vec = None\n",
    "        mat_df['delta_b'] = mat_df['b'].map(lambda x: np.max(x) - np.min(x))\n",
    "\n",
    "        # figure out integral_part \n",
    "        mat_df[\"time_s\"] = mat_df[\"freq\"].map(lambda x: np.linspace(0, 1/x, 1024))\n",
    "\n",
    "        # derivation\n",
    "        # according to https://im-coder.com/zweite-ableitung-in-python-scipy-numpy-pandas.html\n",
    "        mat_df[\"fitted_function\"] = mat_df.apply(lambda x: UnivariateSpline(x[\"time_s\"], x[\"b\"], s=0, k=4), axis=1)\n",
    "        mat_df[\"amplitude_2nd_derivation\"] = mat_df[\"fitted_function\"].apply(lambda x: x.derivative(n=2))\n",
    "        mat_df[\"integrated_function\"] = mat_df.apply(lambda x: trapezoid(np.abs(x[\"amplitude_2nd_derivation\"](x[\"time_s\"])), x[\"time_s\"]), axis=1)     \n",
    "\n",
    "        mat_df[\"integral_part\"] = mat_df[\"integrated_function\"] / mat_df[\"delta_b\"]\n",
    "\n",
    "        \n",
    "        \n",
    "        mat_df[\"rms\"] = np.apply_along_axis(lambda x: np.sqrt(np.mean(np.gradient(np.gradient(x))**2)), 1, full_b)\n",
    "        mat_df[\"rqm\"] = np.apply_along_axis(lambda x: np.sqrt(np.mean(np.gradient(np.gradient(x))**4)), 1, full_b)\n",
    "        mat_df[\"peak\"] = np.apply_along_axis(lambda x: max(np.gradient(np.gradient(x))), 1, full_b)\n",
    "        \n",
    "        # old, non-working examples\n",
    "        #mat_df[\"rms\"]=mat_df.apply(lambda x: np.sqrt(np.mean(np.gradient(np.gradient(x[\"full_b\"]))**2)))\n",
    "        #mat_df[\"rqm\"]=mat_df.apply(lambda x: np.sqrt(np.mean(np.gradient(np.gradient(x[\"full_b\"]))**4)))\n",
    "        #mat_df[\"peak\"] = mat_df.apply(lambda x: max(np.gradient(np.gradient(x[\"full_b\"]))))\n",
    "\n",
    "        \n",
    "\n",
    "        # cross validation 'kfold'\n",
    "        kfold_lbls = get_stratified_fold_indices(mat_df, 4)\n",
    "        mat_df_proc = mat_df.assign(\n",
    "            kfold=kfold_lbls,\n",
    "            # integral_part=mat_df['integral_part'],\n",
    "            #delta_b=mat_df['delta_b'],\n",
    "            #b_sat=mat_df['b_sat_25'],\n",
    "            db_bsat_1 = mat_df['delta_b'] / mat_df['b_sat_25'],\n",
    "            db_bsat_2 = (mat_df['delta_b'] / mat_df['b_sat_25']) ** 2,\n",
    "            db_bsat_3 = (mat_df['delta_b'] / mat_df['b_sat_25']) ** 3,\n",
    "            db_bsat_4 = (mat_df['delta_b'] / mat_df['b_sat_25']) ** 4,\n",
    "            db_bsat_5 = (mat_df['delta_b'] / mat_df['b_sat_25']) ** 5,\n",
    "            db_bsat_6 = (mat_df['delta_b'] / mat_df['b_sat_25']) ** 6,\n",
    "            temp_square = mat_df['temp'] ** 2,\n",
    "            t2 = (mat_df['integral_part'] ** (-1)) / 2,\n",
    "            #t3 = -(mat_df['integral_part'] ** (-2)) / 6,\n",
    "            #t4 = ( 3 * mat_df['integral_part'] ** (-2) + 2 * mat_df['integral_part'] ** (-3)) / 24,\n",
    "            #mean_abs_dbdt=np.mean(np.abs(mat_df[\"delta_b\"])),\n",
    "            rms = mat_df[\"rms\"],\n",
    "            rmq = mat_df[\"rqm\"],\n",
    "            peak = mat_df[\"peak\"],\n",
    "            # more features imaginable (count of spikes e.g.)\n",
    "        ).drop(\n",
    "            columns=[c for c in mat_df if c.startswith(\"B_t_\")] + [\"material\"] + ['b'] + ['time_s'] + ['fitted_function'] +['amplitude_2nd_derivation'] + ['integrated_function'] + ['b_sat_25']\n",
    "        )  # drop B curve\n",
    "\n",
    "        # training result container\n",
    "        results_df = mat_df_proc.loc[:, [\"ploss\", \"kfold\"]].assign(pred=0)\n",
    "        x_cols = [c for c in mat_df_proc if c not in [\"ploss\", \"kfold\"]]\n",
    "        print(x_cols)\n",
    "        for kfold_lbl, test_fold_df in mat_df_proc.groupby(\"kfold\"):\n",
    "            train_fold_df = (\n",
    "                mat_df_proc.query(\"kfold != @kfold_lbl\")\n",
    "                .reset_index(drop=True)\n",
    "                .drop(columns=\"kfold\")\n",
    "            )\n",
    "            assert len(train_fold_df) > 0, \"empty dataframe error\"\n",
    "            y = train_fold_df.pop(\"ploss\")\n",
    "            X = train_fold_df.loc[:, x_cols]\n",
    "\n",
    "            #mdl = GradientBoostingRegressor(n_estimators=n_estimators, criterion=criterion, learning_rate=learning_rate) # GradientBoostingRegressor() # HistGradientBoostingRegressor() # RandomForestRegressor(n_estimators = 100) #LinearRegression() # Ridge()  # \n",
    "            mdl = xgb.XGBRegressor(n_estimators=n_estimators, learning_rate=learning_rate) #, max_depth=max_depth)\n",
    "            mdl.fit(X.to_numpy(), y.to_numpy())\n",
    "            pred = mdl.predict(test_fold_df.loc[:, x_cols].to_numpy())\n",
    "            results_df.loc[results_df.kfold == kfold_lbl, \"pred\"] = pred\n",
    "\n",
    "        # book keeping\n",
    "        exp_log[material_lbl] = calculate_metrics(\n",
    "            np.exp(results_df.loc[:, \"pred\"]), np.exp(results_df.loc[:, \"ploss\"])\n",
    "        )\n",
    "    print(mdl.__class__.__name__)\n",
    "    print(f\"{n_estimators = }\")\n",
    "    print(f\"{learning_rate = }\")\n",
    "    print(mdl.feature_importances_)\n",
    "    \n",
    "    print(\"Overall Score\")\n",
    "    score = pd.DataFrame(exp_log).T\n",
    "    print(score)\n",
    "\n",
    "    added_avg_abs_rel_err = score['avg-abs-rel-err'].sum()\n",
    "    print('sum error')\n",
    "    print(added_avg_abs_rel_err)\n",
    "    \n",
    "    # feature importances\n",
    "    feat_importances = pd.Series(mdl.feature_importances_, index=x_cols)\n",
    "    feat_importances.nlargest(20).plot(kind='barh')\n",
    "    \n",
    "    return added_avg_abs_rel_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mdl.features_importances_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run objective function single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               test\n",
      "0   [1, 2, 3, 4, 5]\n",
      "1  [6, 7, 8, 9, 10]\n",
      "my_df.shape = (2, 1)\n",
      "my_array.shape = (2, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[list([1, 2, 3, 4, 5])],\n",
       "       [list([6, 7, 8, 9, 10])]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# create a Numpy array\n",
    "my_array = np.array([[1, 2, 3, 4, 5], [6,7,8,9,10]])\n",
    "\n",
    "# create a Pandas data frame from the dictionary\n",
    "my_df = pd.DataFrame()\n",
    "\n",
    "my_df[\"test\"] = my_array.tolist()\n",
    "\n",
    "print(my_df)\n",
    "print(f\"{my_df.shape = }\")\n",
    "print(f\"{my_array.shape = }\")\n",
    "\n",
    "my_df.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run objective function in a hyperparameter optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-27 21:47:22,826] A new study created in memory with name: no-name-7ad6bf75-8f6f-4cf0-bcb6-0b5d216b62ec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 463\n",
      "criterion = 'squared_error'\n",
      "learning_rate = 0.22698166594174812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train across materials:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['freq', 'temp', 'delta_b', 'integral_part', 'rms', 'rqm', 'peak', 'db_bsat_1', 'db_bsat_2', 'db_bsat_3', 'db_bsat_4', 'db_bsat_5', 'db_bsat_6', 'temp_square', 't2', 'rmq']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train across materials:  10%|█         | 1/10 [04:07<37:06, 247.34s/it]\n",
      "[W 2023-09-27 21:51:30,197] Trial 0 failed with parameters: {'n_estimators': 463, 'criterion': 'squared_error', 'learning_rate': 0.22698166594174812} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nikolasf/Dokumente/01_git/30_Python/MC_UPB/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1156/1418518545.py\", line 60, in objective\n",
      "    mat_df[\"peak\"] = np.apply_along_axis(lambda x: max(np.gradient(np.gradient(x))), 1, full_b)\n",
      "  File \"<__array_function__ internals>\", line 200, in apply_along_axis\n",
      "  File \"/home/nikolasf/Dokumente/01_git/30_Python/MC_UPB/.venv/lib/python3.10/site-packages/numpy/lib/shape_base.py\", line 402, in apply_along_axis\n",
      "    buff[ind] = asanyarray(func1d(inarr_view[ind], *args, **kwargs))\n",
      "  File \"/tmp/ipykernel_1156/1418518545.py\", line 60, in <lambda>\n",
      "    mat_df[\"peak\"] = np.apply_along_axis(lambda x: max(np.gradient(np.gradient(x))), 1, full_b)\n",
      "KeyboardInterrupt\n",
      "[W 2023-09-27 21:51:30,200] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39m# FYI: Objective functions can take additional arguments\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).\u001b[39;00m\n\u001b[1;32m     13\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     15\u001b[0m \u001b[39m#print(study.best_trial)\u001b[39;00m\n",
      "File \u001b[0;32m~/Dokumente/01_git/30_Python/MC_UPB/.venv/lib/python3.10/site-packages/optuna/study/study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     _optimize(\n\u001b[1;32m    444\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    445\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    446\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    447\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    448\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    449\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    450\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    451\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    452\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    453\u001b[0m     )\n",
      "File \u001b[0;32m~/Dokumente/01_git/30_Python/MC_UPB/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Dokumente/01_git/30_Python/MC_UPB/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/Dokumente/01_git/30_Python/MC_UPB/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/Dokumente/01_git/30_Python/MC_UPB/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[4], line 60\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     58\u001b[0m mat_df[\u001b[39m\"\u001b[39m\u001b[39mrms\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mapply_along_axis(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39msqrt(np\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39mgradient(np\u001b[39m.\u001b[39mgradient(x))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)), \u001b[39m1\u001b[39m, full_b)\n\u001b[1;32m     59\u001b[0m mat_df[\u001b[39m\"\u001b[39m\u001b[39mrqm\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mapply_along_axis(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39msqrt(np\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39mgradient(np\u001b[39m.\u001b[39mgradient(x))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m4\u001b[39m)), \u001b[39m1\u001b[39m, full_b)\n\u001b[0;32m---> 60\u001b[0m mat_df[\u001b[39m\"\u001b[39m\u001b[39mpeak\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mapply_along_axis(\u001b[39mlambda\u001b[39;49;00m x: \u001b[39mmax\u001b[39;49m(np\u001b[39m.\u001b[39;49mgradient(np\u001b[39m.\u001b[39;49mgradient(x))), \u001b[39m1\u001b[39;49m, full_b)\n\u001b[1;32m     62\u001b[0m \u001b[39m# old, non-working examples\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m#mat_df[\"rms\"]=mat_df.apply(lambda x: np.sqrt(np.mean(np.gradient(np.gradient(x[\"full_b\"]))**2)))\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m#mat_df[\"rqm\"]=mat_df.apply(lambda x: np.sqrt(np.mean(np.gradient(np.gradient(x[\"full_b\"]))**4)))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[39m# cross validation 'kfold'\u001b[39;00m\n\u001b[1;32m     70\u001b[0m kfold_lbls \u001b[39m=\u001b[39m get_stratified_fold_indices(mat_df, \u001b[39m4\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Dokumente/01_git/30_Python/MC_UPB/.venv/lib/python3.10/site-packages/numpy/lib/shape_base.py:402\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m buff[ind0] \u001b[39m=\u001b[39m res\n\u001b[1;32m    401\u001b[0m \u001b[39mfor\u001b[39;00m ind \u001b[39min\u001b[39;00m inds:\n\u001b[0;32m--> 402\u001b[0m     buff[ind] \u001b[39m=\u001b[39m asanyarray(func1d(inarr_view[ind], \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    404\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(res, matrix):\n\u001b[1;32m    405\u001b[0m     \u001b[39m# wrap the array, to preserve subclasses\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     buff \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39m__array_wrap__(buff)\n",
      "Cell \u001b[0;32mIn[4], line 60\u001b[0m, in \u001b[0;36mobjective.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     58\u001b[0m mat_df[\u001b[39m\"\u001b[39m\u001b[39mrms\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mapply_along_axis(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39msqrt(np\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39mgradient(np\u001b[39m.\u001b[39mgradient(x))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)), \u001b[39m1\u001b[39m, full_b)\n\u001b[1;32m     59\u001b[0m mat_df[\u001b[39m\"\u001b[39m\u001b[39mrqm\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mapply_along_axis(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39msqrt(np\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39mgradient(np\u001b[39m.\u001b[39mgradient(x))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m4\u001b[39m)), \u001b[39m1\u001b[39m, full_b)\n\u001b[0;32m---> 60\u001b[0m mat_df[\u001b[39m\"\u001b[39m\u001b[39mpeak\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mapply_along_axis(\u001b[39mlambda\u001b[39;00m x: \u001b[39mmax\u001b[39m(np\u001b[39m.\u001b[39mgradient(np\u001b[39m.\u001b[39mgradient(x))), \u001b[39m1\u001b[39m, full_b)\n\u001b[1;32m     62\u001b[0m \u001b[39m# old, non-working examples\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m#mat_df[\"rms\"]=mat_df.apply(lambda x: np.sqrt(np.mean(np.gradient(np.gradient(x[\"full_b\"]))**2)))\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m#mat_df[\"rqm\"]=mat_df.apply(lambda x: np.sqrt(np.mean(np.gradient(np.gradient(x[\"full_b\"]))**4)))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[39m# cross validation 'kfold'\u001b[39;00m\n\u001b[1;32m     70\u001b[0m kfold_lbls \u001b[39m=\u001b[39m get_stratified_fold_indices(mat_df, \u001b[39m4\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import sklearn.model_selection\n",
    "import sklearn.svm\n",
    "\n",
    "# FYI: Objective functions can take additional arguments\n",
    "# (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=3, n_jobs=1)\n",
    "#print(study.best_trial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13 (main, Nov 10 2011, 15:00:00) [GCC 12.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "862f57f7b4a9bcb8e62a2c8b5a26d37db35f8703e11463ebdedd88c83882dd1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
