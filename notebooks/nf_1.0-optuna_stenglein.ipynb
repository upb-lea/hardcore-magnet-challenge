{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary Least Squares on magnet challenge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.integrate import trapezoid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/home/nikolasf/Dokumente/01_git/30_Python/MC_UPB/data/input/processed'\n",
    "material_name = 'ten_materials'\n",
    "ds = pd.read_pickle(f'{filepath}/{material_name}.pkl.gz')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial edit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           2319.444340\n",
      "1           3191.235893\n",
      "2           4341.086142\n",
      "3           5795.359190\n",
      "4           7813.691725\n",
      "              ...      \n",
      "156279     61790.145402\n",
      "156280     78810.500010\n",
      "156281    100717.381914\n",
      "156282    129153.194834\n",
      "156283    165612.702450\n",
      "Name: ploss, Length: 46915, dtype: float64\n",
      "0          7.749083\n",
      "1          8.068164\n",
      "2          8.375880\n",
      "3          8.664813\n",
      "4          8.963633\n",
      "            ...    \n",
      "156279    11.031499\n",
      "156280    11.274802\n",
      "156281    11.520074\n",
      "156282    11.768755\n",
      "156283    12.017407\n",
      "Name: ploss, Length: 46915, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ds = ds.drop(columns=[c for c in ds if c.startswith(\"H_t\")])\n",
    "ds = ds.query('temp == 25')\n",
    "\n",
    "# add the saturation flux density. Data from datasheets.\n",
    "ds.loc[ds['material'] == '3C90', 'b_sat_25'] = 0.47\n",
    "ds.loc[ds['material'] == '3C94', 'b_sat_25'] = 0.47\n",
    "ds.loc[ds['material'] == '3E6', 'b_sat_25'] = 0.46\n",
    "ds.loc[ds['material'] == '3F4', 'b_sat_25'] = 0.41\n",
    "ds.loc[ds['material'] == '77', 'b_sat_25'] = 0.51\n",
    "ds.loc[ds['material'] == '78', 'b_sat_25'] = 0.48\n",
    "ds.loc[ds['material'] == 'N27', 'b_sat_25'] = 0.50\n",
    "ds.loc[ds['material'] == 'N30', 'b_sat_25'] = 0.38\n",
    "ds.loc[ds['material'] == 'N49', 'b_sat_25'] = 0.49\n",
    "ds.loc[ds['material'] == 'N87', 'b_sat_25'] = 0.49\n",
    "\n",
    "\n",
    "print(ds['ploss'])\n",
    "ds['ploss'] = np.log(ds['ploss'])\n",
    "print(ds['ploss'])\n",
    "\n",
    "# print(ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapted Wilhelm example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run linear regression with regularization training\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor, GradientBoostingRegressor, VotingRegressor, ExtraTreesRegressor\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from utils.experiments import get_stratified_fold_indices, PROC_SOURCE\n",
    "from utils.metrics import calculate_metrics\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    n_estimators = 429 # trial.suggest_int('n_estimators', 10, 500)\n",
    "    print(f'{n_estimators = }')\n",
    "    criterion = trial.suggest_categorical('criterion', ['friedman_mse'])\n",
    "    print(f\"{criterion = }\")\n",
    "    learning_rate = 0.12 # trial.suggest_float('learning_rate', 0.01, 1)\n",
    "    print(f\"{learning_rate = }\")\n",
    "    \n",
    "    exp_log = {}\n",
    "    for material_lbl, mat_df in tqdm(ds.groupby(\"material\"), desc=\"Train across materials\"):\n",
    "        full_b = mat_df.loc[:, [f\"B_t_{k}\" for k in range(1024)]].to_numpy()\n",
    "        dbdt = full_b[:, 1:] - full_b[:, :-1]\n",
    "        mat_df = mat_df.reset_index(drop=True)\n",
    "\n",
    "        x_vec = np.linspace(0, 1023, 1024)\n",
    "        b_vec = []\n",
    "        for value in x_vec:\n",
    "            b_vec.append(f'B_t_{int(value)}')\n",
    "        mat_df[\"b\"] = mat_df[b_vec].values.tolist()\n",
    "        x_vec = None\n",
    "        b_vec = None\n",
    "        mat_df['delta_b'] = mat_df['b'].map(lambda x: np.max(x) - np.min(x))\n",
    "\n",
    "        # figure out integral_part \n",
    "        mat_df[\"time_s\"] = mat_df[\"freq\"].map(lambda x: np.linspace(0, 1/x, 1024))\n",
    "\n",
    "        # derivation\n",
    "        # according to https://im-coder.com/zweite-ableitung-in-python-scipy-numpy-pandas.html\n",
    "        mat_df[\"fitted_function\"] = mat_df.apply(lambda x: UnivariateSpline(x[\"time_s\"], x[\"b\"], s=0, k=4), axis=1)\n",
    "        mat_df[\"amplitude_2nd_derivation\"] = mat_df[\"fitted_function\"].apply(lambda x: x.derivative(n=2))\n",
    "        mat_df[\"integrated_function\"] = mat_df.apply(lambda x: trapezoid(np.abs(x[\"amplitude_2nd_derivation\"](x[\"time_s\"])), x[\"time_s\"]), axis=1)     \n",
    "\n",
    "        mat_df[\"integral_part\"] = mat_df[\"integrated_function\"] / mat_df[\"delta_b\"]\n",
    "\n",
    "        # cross validation 'kfold'\n",
    "        kfold_lbls = get_stratified_fold_indices(mat_df, 4)\n",
    "        mat_df_proc = mat_df.assign(\n",
    "            kfold=kfold_lbls,\n",
    "            # integral_part=mat_df['integral_part'],\n",
    "            #delta_b=mat_df['delta_b'],\n",
    "            #b_sat=mat_df['b_sat_25'],\n",
    "            db_bsat_1 = mat_df['delta_b'] / mat_df['b_sat_25'],\n",
    "            db_bsat_2 = (mat_df['delta_b'] / mat_df['b_sat_25']) ** 2,\n",
    "            db_bsat_3 = (mat_df['delta_b'] / mat_df['b_sat_25']) ** 3,\n",
    "            db_bsat_4 = (mat_df['delta_b'] / mat_df['b_sat_25']) ** 4,\n",
    "            db_bsat_5 = (mat_df['delta_b'] / mat_df['b_sat_25']) ** 5,\n",
    "            db_bsat_6 = (mat_df['delta_b'] / mat_df['b_sat_25']) ** 6,\n",
    "            t0 = 1,\n",
    "            t1 = 0,\n",
    "            t2 = (mat_df['integral_part'] ** (-1)) / 2,\n",
    "            t3 = -(mat_df['integral_part'] ** (-2)) / 6,\n",
    "            t4 = ( 3 * mat_df['integral_part'] ** (-2) + 2 * mat_df['integral_part'] ** (-3)) / 24\n",
    "            # more features imaginable (count of spikes e.g.)\n",
    "        ).drop(\n",
    "            columns=[c for c in mat_df if c.startswith(\"B_t_\")] + [\"material\"] + ['b'] + ['time_s'] + ['fitted_function'] +['amplitude_2nd_derivation'] + ['integrated_function'] + ['temp'] + ['b_sat_25']\n",
    "        )  # drop B curve\n",
    "\n",
    "        # training result container\n",
    "        results_df = mat_df_proc.loc[:, [\"ploss\", \"kfold\"]].assign(pred=0)\n",
    "        x_cols = [c for c in mat_df_proc if c not in [\"ploss\", \"kfold\"]]\n",
    "        print(x_cols)\n",
    "        for kfold_lbl, test_fold_df in mat_df_proc.groupby(\"kfold\"):\n",
    "            train_fold_df = (\n",
    "                mat_df_proc.query(\"kfold != @kfold_lbl\")\n",
    "                .reset_index(drop=True)\n",
    "                .drop(columns=\"kfold\")\n",
    "            )\n",
    "            assert len(train_fold_df) > 0, \"empty dataframe error\"\n",
    "            y = train_fold_df.pop(\"ploss\")\n",
    "            X = train_fold_df.loc[:, x_cols]\n",
    "\n",
    "            mdl = GradientBoostingRegressor(n_estimators=n_estimators, criterion=criterion, learning_rate=learning_rate) # GradientBoostingRegressor() # HistGradientBoostingRegressor() # RandomForestRegressor(n_estimators = 100) #LinearRegression() # Ridge()  # \n",
    "            mdl.fit(X.to_numpy(), y.to_numpy())\n",
    "            pred = mdl.predict(test_fold_df.loc[:, x_cols].to_numpy())\n",
    "            results_df.loc[results_df.kfold == kfold_lbl, \"pred\"] = pred\n",
    "\n",
    "        # book keeping\n",
    "        exp_log[material_lbl] = calculate_metrics(\n",
    "            np.exp(results_df.loc[:, \"pred\"]), np.exp(results_df.loc[:, \"ploss\"])\n",
    "        )\n",
    "    print(mdl.__class__.__name__)\n",
    "    print(f\"{n_estimators = }\")\n",
    "    print(f\"{learning_rate = }\")\n",
    "    #print(mdl.features_importances_)\n",
    "    \n",
    "    print(\"Overall Score\")\n",
    "    score = pd.DataFrame(exp_log).T\n",
    "    print(score)\n",
    "\n",
    "    added_avg_abs_rel_err = score['avg-abs-rel-err'].sum()\n",
    "    print('sum error')\n",
    "    print(added_avg_abs_rel_err)\n",
    "    \n",
    "    return added_avg_abs_rel_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(mdl.features_importances_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run objective function single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run objective function in a hyperparameter optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-01 08:50:36,506] A new study created in memory with name: no-name-e0f808de-0d87-4c0c-aecd-f35deaa82db9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 429\n",
      "criterion = 'friedman_mse'\n",
      "learning_rate = 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train across materials:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['freq', 'delta_b', 'integral_part', 'db_bsat_1', 'db_bsat_2', 'db_bsat_3', 'db_bsat_4', 'db_bsat_5', 'db_bsat_6', 't0', 't1', 't2', 't3', 't4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train across materials:  10%|█         | 1/10 [01:13<11:01, 73.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['freq', 'delta_b', 'integral_part', 'db_bsat_1', 'db_bsat_2', 'db_bsat_3', 'db_bsat_4', 'db_bsat_5', 'db_bsat_6', 't0', 't1', 't2', 't3', 't4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train across materials:  20%|██        | 2/10 [02:28<09:52, 74.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['freq', 'delta_b', 'integral_part', 'db_bsat_1', 'db_bsat_2', 'db_bsat_3', 'db_bsat_4', 'db_bsat_5', 'db_bsat_6', 't0', 't1', 't2', 't3', 't4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train across materials:  30%|███       | 3/10 [02:41<05:24, 46.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['freq', 'delta_b', 'integral_part', 'db_bsat_1', 'db_bsat_2', 'db_bsat_3', 'db_bsat_4', 'db_bsat_5', 'db_bsat_6', 't0', 't1', 't2', 't3', 't4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train across materials:  40%|████      | 4/10 [02:55<03:21, 33.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['freq', 'delta_b', 'integral_part', 'db_bsat_1', 'db_bsat_2', 'db_bsat_3', 'db_bsat_4', 'db_bsat_5', 'db_bsat_6', 't0', 't1', 't2', 't3', 't4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train across materials:  50%|█████     | 5/10 [03:15<02:23, 28.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['freq', 'delta_b', 'integral_part', 'db_bsat_1', 'db_bsat_2', 'db_bsat_3', 'db_bsat_4', 'db_bsat_5', 'db_bsat_6', 't0', 't1', 't2', 't3', 't4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train across materials:  60%|██████    | 6/10 [03:43<01:53, 28.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['freq', 'delta_b', 'integral_part', 'db_bsat_1', 'db_bsat_2', 'db_bsat_3', 'db_bsat_4', 'db_bsat_5', 'db_bsat_6', 't0', 't1', 't2', 't3', 't4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train across materials:  70%|███████   | 7/10 [04:03<01:17, 25.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['freq', 'delta_b', 'integral_part', 'db_bsat_1', 'db_bsat_2', 'db_bsat_3', 'db_bsat_4', 'db_bsat_5', 'db_bsat_6', 't0', 't1', 't2', 't3', 't4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train across materials:  80%|████████  | 8/10 [04:20<00:45, 22.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['freq', 'delta_b', 'integral_part', 'db_bsat_1', 'db_bsat_2', 'db_bsat_3', 'db_bsat_4', 'db_bsat_5', 'db_bsat_6', 't0', 't1', 't2', 't3', 't4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train across materials:  90%|█████████ | 9/10 [04:35<00:20, 20.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['freq', 'delta_b', 'integral_part', 'db_bsat_1', 'db_bsat_2', 'db_bsat_3', 'db_bsat_4', 'db_bsat_5', 'db_bsat_6', 't0', 't1', 't2', 't3', 't4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train across materials: 100%|██████████| 10/10 [05:46<00:00, 34.65s/it]\n",
      "[I 2023-09-01 08:56:23,194] Trial 0 finished with value: 0.8605990165875625 and parameters: {'criterion': 'friedman_mse'}. Best is trial 0 with value: 0.8605990165875625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor\n",
      "n_estimators = 429\n",
      "learning_rate = 0.12\n",
      "Overall Score\n",
      "               mse           mae  avg-abs-rel-err  percentile_5_rel_err  \\\n",
      "3C90  7.046213e+08  12222.947832         0.092755              0.005449   \n",
      "3C94  2.006546e+09  20709.790009         0.092965              0.006054   \n",
      "3E6   4.597660e+09  33245.532382         0.085069              0.005876   \n",
      "3F4   7.293612e+08   9697.432630         0.058616              0.004035   \n",
      "77    2.444026e+09  22798.598061         0.097164              0.006124   \n",
      "78    1.703914e+09  18989.606688         0.097450              0.006583   \n",
      "N27   2.313452e+09  21663.224465         0.075091              0.004891   \n",
      "N30   5.115155e+09  31634.673170         0.085142              0.006145   \n",
      "N49   3.939435e+09  30377.704650         0.099155              0.005876   \n",
      "N87   5.543226e+08  11180.969596         0.077192              0.005165   \n",
      "\n",
      "      percentile_95_rel_err       l_infty   l_infty_over  l_infty_under  \n",
      "3C90               0.271576  3.095596e+05  185472.807837  -3.095596e+05  \n",
      "3C94               0.266574  6.356433e+05  262658.007934  -6.356433e+05  \n",
      "3E6                0.246330  7.203324e+05  515775.347623  -7.203324e+05  \n",
      "3F4                0.162360  3.489938e+05  227600.790823  -3.489938e+05  \n",
      "77                 0.270190  5.620395e+05  232073.640760  -5.620395e+05  \n",
      "78                 0.280162  4.149729e+05  246758.372018  -4.149729e+05  \n",
      "N27                0.205589  4.445670e+05  238158.492060  -4.445670e+05  \n",
      "N30                0.217785  1.001180e+06  568571.943688  -1.001180e+06  \n",
      "N49                0.311356  5.953556e+05  328835.221564  -5.953556e+05  \n",
      "N87                0.218519  3.218999e+05  177641.372700  -3.218999e+05  \n",
      "sum error\n",
      "0.8605990165875625\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import sklearn.model_selection\n",
    "import sklearn.svm\n",
    "\n",
    "\n",
    "# FYI: Objective functions can take additional arguments\n",
    "# (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=1, n_jobs=1)\n",
    "#print(study.best_trial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "862f57f7b4a9bcb8e62a2c8b5a26d37db35f8703e11463ebdedd88c83882dd1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
